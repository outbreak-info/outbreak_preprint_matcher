{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook investigates the performance of the preprint-matcher algorithm\n",
    "To investigate the precision and accuracy of the results from the preprint matcher, this notebook will:\n",
    "1. Pull all preprints from the Pubmed pilot period\n",
    "2. Parse out the pmid of the corresponding peer-reviewed publication\n",
    "3. Check Litcovid for the corresponding peer-reviewed publication\n",
    "4. Analyze the results for number of pmids found by both the preprint matcher and the pubmed pilot, and the number of pmids found by each method only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import json\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "from src.archive_functions import generate_updates\n",
    "from src.archive_functions import generate_split_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_preprints(recordList):\n",
    "    results = []\n",
    "    for PMID in recordList:\n",
    "        handle = Entrez.efetch(db=\"pubmed\", id=PMID, rettype=\"medline\", retmode=\"text\")\n",
    "        records = Medline.parse(handle) ##parses pubmed entry for that ID \n",
    "        for record in records:\n",
    "            rec_dict = {\n",
    "                'preprintPMID':record['PMID'],\n",
    "                'preprint_citation':record['SO'],\n",
    "                'publicationType':record['PT']\n",
    "            }\n",
    "            try:\n",
    "                rec_dict['updatedInfo']=record['UIN']\n",
    "                results.append(rec_dict)\n",
    "            except:\n",
    "                rec_dict['updatedInfo']='could not parse'\n",
    "                results.append(rec_dict)\n",
    "            \n",
    "            time.sleep(0.5)\n",
    "    resultdf = pd.DataFrame(results)\n",
    "    return(resultdf)\n",
    "\n",
    "def parse_pmid(entry):\n",
    "    tmp = entry[0].split(':')\n",
    "    pmid = tmp[-1].strip()\n",
    "    return(pmid)\n",
    "\n",
    "def parse_doi(entry):\n",
    "    tmp = entry.split(\":\")\n",
    "    doi = tmp[-1].strip()\n",
    "    return(doi)\n",
    "\n",
    "def parse_journal(entry):\n",
    "    tmp = entry.split(\":\")\n",
    "    tmp2 = tmp[0].split(\".\")\n",
    "    journal = tmp2[0]\n",
    "    return(journal)    \n",
    "\n",
    "def fetch_pubmed_preprints(email_address):\n",
    "    Entrez.email=email_address\n",
    "    handle = Entrez.esearch(db=\"pubmed\", RetMax=5000, term=\"preprint[Publication Type]\")\n",
    "    records = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    recordList = records['IdList']\n",
    "    return(recordList)\n",
    "\n",
    "def load_litcovid_ids(ARCHIVEPATH):\n",
    "    with open(os.path.join(ARCHIVEPATH,'all_litcovid_dict.txt'),'rb') as infile:\n",
    "        all_litcovid_dict = pickle.load(infile)\n",
    "    key = list(all_litcovid_dict.keys())\n",
    "    all_litcovid_ids = list(all_litcovid_dict[key[0]])\n",
    "    return(all_litcovid_ids)\n",
    "\n",
    "def doi_to_id(entry):\n",
    "    no_end_period = entry.rstrip('.')\n",
    "    no_versions = re.sub(r\"\\/v\\d\",\"\",no_end_period)\n",
    "    split_out_slashes = no_versions.split('/')\n",
    "    the_id = split_out_slashes[-1]\n",
    "    return(the_id)\n",
    "\n",
    "def parse_records(recordList,ARCHIVEPATH):\n",
    "    resultdf = parse_preprints(recordList)\n",
    "    has_update = resultdf.loc[resultdf['updatedInfo']!='could not parse'].copy()\n",
    "    has_update['updatedPMID'] = has_update.apply(lambda row: parse_pmid(row['updatedInfo']),axis=1)\n",
    "    all_litcovid_ids = load_litcovid_ids(ARCHIVEPATH)\n",
    "    has_update['outbreak_update_pmids']=['pmid'+str(x) for x in has_update['updatedPMID']]\n",
    "    has_litcovid = has_update.loc[has_update['outbreak_update_pmids'].isin(all_litcovid_ids)].copy()\n",
    "    has_litcovid['doi'] = has_litcovid.apply(lambda row: parse_doi(row['preprint_citation']),axis=1)\n",
    "    has_litcovid['preprint journal'] = has_litcovid.apply(lambda row: parse_journal(row['preprint_citation']),axis=1)\n",
    "    has_litcovid['outbreak_preprint_id'] = has_litcovid.apply(lambda row:doi_to_id(row['doi']),axis=1)\n",
    "    return(has_litcovid)\n",
    "\n",
    "\n",
    "def transform_results(has_litcovid):\n",
    "    from_rxiv = has_litcovid.loc[has_litcovid['preprint journal'].astype(str).str.contains('Rxiv')]\n",
    "    updatedf = from_rxiv[['outbreak_update_pmids','outbreak_preprint_id']].copy()\n",
    "    updatedf.rename(columns={'outbreak_update_pmids':'litcovid','outbreak_preprint_id':'preprint'},inplace=True)\n",
    "    return(updatedf)\n",
    "\n",
    "\n",
    "def pull_updates_from_pubmed(email_address,ARCHIVEPATH,OUTPUTPATH):\n",
    "    recordList = fetch_pubmed_preprints(email_address)\n",
    "    has_litcovid = parse_records(recordList,ARCHIVEPATH)\n",
    "    updatedf = transform_results(has_litcovid)\n",
    "    generate_updates(updatedf,OUTPUTPATH)\n",
    "    generate_split_updates(updatedf,OUTPUTPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Note this one is just for testing (use in conjunction of archived update file)\n",
    "def parse_records(has_update,ARCHIVEPATH):\n",
    "    #resultdf = parse_preprints(recordList)\n",
    "    #has_update = resultdf.loc[resultdf['updatedInfo']!='could not parse'].copy()\n",
    "    has_update['updatedPMID'] = has_update.apply(lambda row: parse_pmid(row['updatedInfo']),axis=1)\n",
    "    all_litcovid_ids = load_litcovid_ids(ARCHIVEPATH)\n",
    "    has_update['outbreak_update_pmids']=['pmid'+str(x) for x in has_update['updatedPMID']]\n",
    "    has_litcovid = has_update.loc[has_update['outbreak_update_pmids'].isin(all_litcovid_ids)].copy()\n",
    "    has_litcovid['doi'] = has_litcovid.apply(lambda row: parse_doi(row['preprint_citation']),axis=1)\n",
    "    has_litcovid['preprint journal'] = has_litcovid.apply(lambda row: parse_journal(row['preprint_citation']),axis=1)\n",
    "    has_litcovid['outbreak_preprint_id'] = has_litcovid.apply(lambda row:doi_to_id(row['doi']),axis=1)\n",
    "    return(has_litcovid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.92 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.config import email_address\n",
    "scriptpath = ''\n",
    "RESULTSPATH = os.path.join(scriptpath,'results/')\n",
    "ARCHIVEPATH = os.path.join(RESULTSPATH,'archives/')\n",
    "OUTPUTPATH = os.path.join(RESULTSPATH,'update dumps/')\n",
    "#pull_updates_from_pubmed(email_address,ARCHIVEPATH,OUTPUTPATH)\n",
    "#recordList = fetch_pubmed_preprints(email_address)\n",
    "#has_litcovid = parse_records(recordList,ARCHIVEPATH)\n",
    "#updatedf = transform_results(has_litcovid)\n",
    "#generate_updates(updatedf,OUTPUTPATH)\n",
    "#generate_split_updates(updatedf,OUTPUTPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### Fetch all preprints fromn PubMed\n",
    "\n",
    "#handle = Entrez.esearch(db=\"pubmed\", RetMax=5000, term=\"(COVID OR SARS OR pandemic OR Coronavirus) AND (preprint[Publication Type])\")\n",
    "handle = Entrez.esearch(db=\"pubmed\", RetMax=5000, term=\"preprint[Publication Type]\")\n",
    "records = Entrez.read(handle)\n",
    "handle.close()\n",
    "recordList = records['IdList']\n",
    "print(len(recordList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### Parse out the corresponding peer-reviewed version PMIDs\n",
    "resultdf = parse_preprints(recordList)\n",
    "has_update = resultdf.loc[resultdf['updatedInfo']!='could not parse'].copy()\n",
    "has_update['updatedPMID'] = has_update.apply(lambda row: parse_pmid(row['updatedInfo']),axis=1)\n",
    "#pmids = parse_pmid(has_update.iloc[0]['updatedInfo'])\n",
    "print(has_update.head(n=2))\n",
    "with open('data/pubmed_preprints.pickle','wb') as outfile:\n",
    "    pickle.dump(has_update,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pubmed_preprints.pickle','rb') as infile:\n",
    "    has_update = pickle.load(infile)\n",
    "\n",
    "has_update.to_csv('results/has_updates.tsv',sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Check if the peer-reviewed version is in our import of LitCovid\n",
    "#### If it is, keep it--otherwise, discard it\n",
    "scriptpath = ''\n",
    "RESULTSPATH = os.path.join(scriptpath,'results/')\n",
    "ARCHIVEPATH = os.path.join(RESULTSPATH,'archives/')\n",
    "OUTPUTPATH = os.path.join(RESULTSPATH,'update dumps/')\n",
    "has_litcovid = parse_records(has_update,ARCHIVEPATH)\n",
    "\n",
    "#### parse out the preprint dois\n",
    "updatedf = transform_results(has_litcovid)\n",
    "print(updatedf.head(n=2))\n",
    "\n",
    "#### export results:\n",
    "generate_updates(updatedf,OUTPUTPATH)\n",
    "generate_split_updates(updatedf,OUTPUTPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### Check overlap with preprint-matching algorithm results\n",
    "litcovid_matches = read_csv('results/update dumps/litcovid_update_file.tsv', delimiter='\\t',header=0, index_col=0)\n",
    "matcher_litcovid_set = set(litcovid_matches['_id'].unique().tolist())\n",
    "pubmed_litcovid_set = set(has_litcovid['outbreak_update_pmids'].unique().tolist())\n",
    "in_common = matcher_litcovid_set.intersection(pubmed_litcovid_set)\n",
    "preprint_matcher_only = [x for x in list(matcher_litcovid_set) if x not in list(pubmed_litcovid_set)]\n",
    "pubmed_litcovid_only = [x for x in list(pubmed_litcovid_set) if x not in list(matcher_litcovid_set)]\n",
    "\n",
    "print(\"Number of matches found by preprint matcher: \", len(matcher_litcovid_set))\n",
    "print(\"Number of matches found by pubmed pilot: \", len(pubmed_litcovid_set))\n",
    "print(\"Number of matches found by both: \",len(in_common))\n",
    "print(\"Number of matches found only by preprint matcher: \",len(preprint_matcher_only))\n",
    "print(\"Number of matches found only by pubmed pilot: \", len(pubmed_litcovid_only))\n",
    "\n",
    "\"\"\"\n",
    "previous results:\n",
    "Number of matches found by preprint matcher:  1662\n",
    "Number of matches found by pubmed pilot:  1259\n",
    "Number of matches found by both:  194\n",
    "Number of matches found only by preprint matcher:  1468\n",
    "Number of matches found only by pubmed pilot:  1065\n",
    "Wall time: 178 ms\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Check overlap with the \"needs review matches\"\n",
    "manual_check = read_csv('results/to review/manual_check.txt', delimiter='\\t',header=0,index_col=0)\n",
    "#print(manual_check.head(n=2))\n",
    "manual_check_set = set(manual_check['litcovid'].unique().tolist())\n",
    "manual_in_common = manual_check_set.intersection(pubmed_litcovid_set)\n",
    "manual_check_only = [x for x in list(manual_check_set) if x not in list(pubmed_litcovid_set)]\n",
    "pubmed_litcovid_only_truly = [x for x in list(pubmed_litcovid_only) if x not in list(manual_check_set)]\n",
    "\n",
    "print(\"Number of matches found by preprint matcher to review: \", len(manual_check_set))\n",
    "print(\"Number of matches found by pubmed pilot: \", len(pubmed_litcovid_set))\n",
    "print(\"Number of matches found by both: \",len(manual_in_common))\n",
    "print(\"Number of matches found only by preprint matcher to review: \",len(manual_check_only))\n",
    "print(\"Number of matches found only by pubmed pilot: \", len(pubmed_litcovid_only_truly))\n",
    "\n",
    "\"\"\"\n",
    "Previous results:\n",
    "\n",
    "print(\"Number of matches found by preprint matcher to review: \", len(manual_check_set))\n",
    "print(\"Number of matches found by pubmed pilot: \", len(pubmed_litcovid_set))\n",
    "print(\"Number of matches found by both: \",len(manual_in_common))\n",
    "print(\"Number of matches found only by preprint matcher to review: \",len(manual_check_only))\n",
    "print(\"Number of matches found only by pubmed pilot: \", len(pubmed_litcovid_only_truly))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_unique_pilot = has_litcovid.loc[has_litcovid['outbreak_update_pmids'].isin(pubmed_litcovid_only_truly)]\n",
    "print(pubmed_unique_pilot.groupby('preprint journal').size().reset_index(name=\"counts\"))\n",
    "print(pubmed_unique_pilot['preprintPMID'].loc[pubmed_unique_pilot['preprint journal']=='bioRxiv'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Unit text\n",
    "\n",
    "PMID = \"33948449\"\n",
    "handle = Entrez.efetch(db=\"pubmed\", id=PMID, rettype=\"medline\", retmode=\"text\")\n",
    "records = Medline.parse(handle) ##parses pubmed entry for that ID and records the author\n",
    "results = []\n",
    "for record in records:\n",
    "    rec_dict = {\n",
    "        'preprintPMID':record['PMID'],\n",
    "        'preprint_citation':record['SO']\n",
    "        'publicationType':record['PT']\n",
    "        'updatedIn':record['UIN']\n",
    "    }\n",
    "    try:\n",
    "        tmp = record['UIN']\n",
    "        tmplist = tmp.split(':')\n",
    "        UIN_PMID = tmplist[-1]\n",
    "        rec_dict['updated in']=UIN_PMID\n",
    "    except:\n",
    "        rec_dict['updated in']='could not parse'\n",
    "    results.append(rec_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "test = ['10.21203/rs.3.rs-700296/v1.','10.1101/2021.07.08.21259776.','10.1101/2021.07.07.451505.']\n",
    "test1 = re.sub(r\"\\/v\\d\",\"\",test[0])\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/archives/all_litcovid_dict.txt','rb') as infile:\n",
    "    all_litcovid_dict = pickle.load(infile)\n",
    "print(len(all_litcovid_dict['2021-09-21']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Preprints for note on peer-reviewed version\n",
    "\n",
    "1. Import list of preprint urls and their expected pmid matches\n",
    "2. Search for text: \"Now published in\"\n",
    "3. Extract journal and doi\n",
    "4. Pull journal titles and dois for PMIDs\n",
    "5. Put it in a table for manual review\n",
    "\n",
    "It looks like bioRxiv/medRxiv use HighWire Citation services to pull in the link to the peer-reviewed version, and the information is not available when scraping the site.\n",
    "\n",
    "The information is found in a `<div>` that does not appear in the html retrieved via requests. See example below which cannot be found in the html via requests library.\n",
    "```\n",
    "<div class=\"pub_jnl\" style=\"padding-top:8px;font-size:11pt;line-height:1.25em;color:#BC2635;\">Now published in <i>PLOS ONE</i> doi: <a href=\"https://doi.org/10.1371/journal.pone.0233145\" target=\"_blank\" style=\"color:#BC2635;\">10.1371/journal.pone.0233145</a></div>\n",
    "```\n",
    "\n",
    "We can still use the pmids to pull the journal name and doi to shorten the review process though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 preprint_link  \\\n",
      "0  https://doi.org/10.1101/2020.05.01.20081026   \n",
      "1  https://doi.org/10.1101/2020.03.10.20033852   \n",
      "\n",
      "                                  pmid_link      pmid  \n",
      "0  https://pubmed.ncbi.nlm.nih.gov/32584972  32584972  \n",
      "1  https://pubmed.ncbi.nlm.nih.gov/32637423  32637423  \n"
     ]
    }
   ],
   "source": [
    "to_check = pd.read_csv('results/to review/check_preprints.tsv', delimiter='\\t',header=0)\n",
    "print(to_check.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(to_check.iloc[0]['preprint_link'])\n",
    "print(to_check.iloc[0]['preprint_link'])\n",
    "raw = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmidlist = to_check['pmid'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pmid                                            journal  \\\n",
      "0  32584972  Clinical infectious diseases : an official pub...   \n",
      "1  32637423                              Frontiers in medicine   \n",
      "\n",
      "            journalAbbr  \n",
      "0       Clin Infect Dis  \n",
      "1  Front Med (Lausanne)  \n",
      "Wall time: 9min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "for PMID in pmidlist:\n",
    "    Entrez.email=email_address\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=PMID, rettype=\"medline\", retmode=\"text\")\n",
    "    records = Medline.parse(handle) ##parses pubmed entry for that ID \n",
    "    for record in records:\n",
    "        rec_dict = {\n",
    "            'pmid':PMID,\n",
    "            'journal':record['JT'],\n",
    "            'journalAbbr':record['TA']\n",
    "        }\n",
    "        results.append(rec_dict)\n",
    "        time.sleep(0.5)\n",
    "resultdf = pd.DataFrame(results)\n",
    "print(resultdf.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf.to_csv('results/to review/publication_journals.tsv',sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative method for checking preprint matcher vs pubmed pilot\n",
    "To investigate the precision and accuracy of the results from the preprint matcher, this notebook will:\n",
    "1. Pull all LitCovid IDs with a 'corrections' field\n",
    "2. Filter only for 'corrections' fields where the values is 'update of' (litcovid itself does not contain preprints, so the corresponding field, 'update in', should not be present)\n",
    "3. Pull the corresponding pmid\n",
    "4. Map the pmid via doi matching to biorxiv/medrxiv preprints\n",
    "5. Analyze the results for number of true positives, false positives, and false negatives to get an idea of precision and sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch all LitCovid IDs with a 'corrections' field from the API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter for 'corrections' field where value contains 'update of'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter for 'corrections' field where value contains 'preprint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch Retraction links: ROF - Obes Res Clin Pract. 2020 Jul - Aug;14(4):295-300. PMID: 32660813"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
