{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook investigates the performance of the preprint-matcher algorithm\n",
    "To investigate the precision and accuracy of the results from the preprint matcher, this notebook will:\n",
    "1. Pull all preprints from the Pubmed pilot period\n",
    "2. Parse out the pmid of the corresponding peer-reviewed publication\n",
    "3. Check Litcovid for the corresponding peer-reviewed publication\n",
    "4. Analyze the results for number of pmids found by both the preprint matcher and the pubmed pilot, and the number of pmids found by each method only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import json\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "from src.archive_functions import generate_updates\n",
    "from src.archive_functions import generate_split_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_preprints(recordList):\n",
    "    results = []\n",
    "    for PMID in recordList:\n",
    "        handle = Entrez.efetch(db=\"pubmed\", id=PMID, rettype=\"medline\", retmode=\"text\")\n",
    "        records = Medline.parse(handle) ##parses pubmed entry for that ID \n",
    "        for record in records:\n",
    "            rec_dict = {\n",
    "                'preprintPMID':record['PMID'],\n",
    "                'preprint_citation':record['SO'],\n",
    "                'publicationType':record['PT']\n",
    "            }\n",
    "            try:\n",
    "                rec_dict['updatedInfo']=record['UIN']\n",
    "                results.append(rec_dict)\n",
    "            except:\n",
    "                rec_dict['updatedInfo']='could not parse'\n",
    "                results.append(rec_dict)\n",
    "            \n",
    "            time.sleep(0.5)\n",
    "    resultdf = pd.DataFrame(results)\n",
    "    return(resultdf)\n",
    "\n",
    "def parse_pmid(entry):\n",
    "    tmp = entry[0].split(':')\n",
    "    pmid = tmp[-1].strip()\n",
    "    return(pmid)\n",
    "\n",
    "def parse_doi(entry):\n",
    "    tmp = entry.split(\":\")\n",
    "    doi = tmp[-1].strip()\n",
    "    return(doi)\n",
    "\n",
    "def parse_journal(entry):\n",
    "    tmp = entry.split(\":\")\n",
    "    tmp2 = tmp[0].split(\".\")\n",
    "    journal = tmp2[0]\n",
    "    return(journal)    \n",
    "\n",
    "def fetch_pubmed_preprints(email_address):\n",
    "    Entrez.email=email_address\n",
    "    handle = Entrez.esearch(db=\"pubmed\", RetMax=5000, term=\"preprint[Publication Type]\")\n",
    "    records = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    recordList = records['IdList']\n",
    "    return(recordList)\n",
    "\n",
    "def load_litcovid_ids(ARCHIVEPATH):\n",
    "    with open(os.path.join(ARCHIVEPATH,'all_litcovid_dict.txt'),'rb') as infile:\n",
    "        all_litcovid_dict = pickle.load(infile)\n",
    "    key = list(all_litcovid_dict.keys())\n",
    "    all_litcovid_ids = list(all_litcovid_dict[key[0]])\n",
    "    return(all_litcovid_ids)\n",
    "\n",
    "def doi_to_id(entry):\n",
    "    no_end_period = entry.rstrip('.')\n",
    "    no_versions = re.sub(r\"\\/v\\d\",\"\",no_end_period)\n",
    "    split_out_slashes = no_versions.split('/')\n",
    "    the_id = split_out_slashes[-1]\n",
    "    return(the_id)\n",
    "\n",
    "def parse_records(recordList,ARCHIVEPATH):\n",
    "    resultdf = parse_preprints(recordList)\n",
    "    has_update = resultdf.loc[resultdf['updatedInfo']!='could not parse'].copy()\n",
    "    has_update['updatedPMID'] = has_update.apply(lambda row: parse_pmid(row['updatedInfo']),axis=1)\n",
    "    all_litcovid_ids = load_litcovid_ids(ARCHIVEPATH)\n",
    "    has_update['outbreak_update_pmids']=['pmid'+str(x) for x in has_update['updatedPMID']]\n",
    "    has_litcovid = has_update.loc[has_update['outbreak_update_pmids'].isin(all_litcovid_ids)].copy()\n",
    "    has_litcovid['doi'] = has_litcovid.apply(lambda row: parse_doi(row['preprint_citation']),axis=1)\n",
    "    has_litcovid['preprint journal'] = has_litcovid.apply(lambda row: parse_journal(row['preprint_citation']),axis=1)\n",
    "    has_litcovid['outbreak_preprint_id'] = has_litcovid.apply(lambda row:doi_to_id(row['doi']),axis=1)\n",
    "    return(has_litcovid)\n",
    "\n",
    "\n",
    "def transform_results(has_litcovid):\n",
    "    from_rxiv = has_litcovid.loc[has_litcovid['preprint journal'].astype(str).str.contains('Rxiv')]\n",
    "    updatedf = from_rxiv[['outbreak_update_pmids','outbreak_preprint_id']].copy()\n",
    "    updatedf.rename(columns={'outbreak_update_pmids':'litcovid','outbreak_preprint_id':'preprint'},inplace=True)\n",
    "    return(updatedf)\n",
    "\n",
    "\n",
    "def pull_updates_from_pubmed(email_address,ARCHIVEPATH,OUTPUTPATH):\n",
    "    recordList = fetch_pubmed_preprints(email_address)\n",
    "    has_litcovid = parse_records(recordList,ARCHIVEPATH)\n",
    "    updatedf = transform_results(has_litcovid)\n",
    "    generate_updates(updatedf,OUTPUTPATH)\n",
    "    generate_split_updates(updatedf,OUTPUTPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Note this one is just for testing (use in conjunction of archived update file)\n",
    "def parse_records(has_update,ARCHIVEPATH):\n",
    "    #resultdf = parse_preprints(recordList)\n",
    "    #has_update = resultdf.loc[resultdf['updatedInfo']!='could not parse'].copy()\n",
    "    has_update['updatedPMID'] = has_update.apply(lambda row: parse_pmid(row['updatedInfo']),axis=1)\n",
    "    all_litcovid_ids = load_litcovid_ids(ARCHIVEPATH)\n",
    "    has_update['outbreak_update_pmids']=['pmid'+str(x) for x in has_update['updatedPMID']]\n",
    "    has_litcovid = has_update.loc[has_update['outbreak_update_pmids'].isin(all_litcovid_ids)].copy()\n",
    "    has_litcovid['doi'] = has_litcovid.apply(lambda row: parse_doi(row['preprint_citation']),axis=1)\n",
    "    has_litcovid['preprint journal'] = has_litcovid.apply(lambda row: parse_journal(row['preprint_citation']),axis=1)\n",
    "    has_litcovid['outbreak_preprint_id'] = has_litcovid.apply(lambda row:doi_to_id(row['doi']),axis=1)\n",
    "    return(has_litcovid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 400: Bad Request",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-062b4c24877c>\u001b[0m in \u001b[0;36mpull_updates_from_pubmed\u001b[1;34m(email_address, ARCHIVEPATH, OUTPUTPATH)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpull_updates_from_pubmed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memail_address\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mARCHIVEPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mOUTPUTPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mrecordList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_pubmed_preprints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memail_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mhas_litcovid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecordList\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mARCHIVEPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[0mupdatedf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhas_litcovid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mgenerate_updates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdatedf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mOUTPUTPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-062b4c24877c>\u001b[0m in \u001b[0;36mparse_records\u001b[1;34m(recordList, ARCHIVEPATH)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mparse_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecordList\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mARCHIVEPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mresultdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_preprints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecordList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[0mhas_update\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresultdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresultdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'updatedInfo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m'could not parse'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mhas_update\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'updatedPMID'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhas_update\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mparse_pmid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'updatedInfo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-062b4c24877c>\u001b[0m in \u001b[0;36mparse_preprints\u001b[1;34m(recordList)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mPMID\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrecordList\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEntrez\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mefetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pubmed\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPMID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrettype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"medline\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mrecords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMedline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m##parses pubmed entry for that ID\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrecord\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\lib\\site-packages\\Bio\\Entrez\\__init__.py\u001b[0m in \u001b[0;36mefetch\u001b[1;34m(db, **keywords)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[1;31m# more than about 200 IDs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mpost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcgi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\lib\\site-packages\\Bio\\Entrez\\__init__.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(cgi, params, post, ecitmatch)\u001b[0m\n\u001b[0;32m    602\u001b[0m                 \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcgi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m                 \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcgi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m             \u001b[1;31m# Reraise if the final try fails\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[1;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             response = self.parent.error(\n\u001b[0m\u001b[0;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\outbreak\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.config import email_address\n",
    "scriptpath = ''\n",
    "RESULTSPATH = os.path.join(scriptpath,'results/')\n",
    "ARCHIVEPATH = os.path.join(RESULTSPATH,'archives/')\n",
    "OUTPUTPATH = os.path.join(RESULTSPATH,'update dumps/')\n",
    "pull_updates_from_pubmed(email_address,ARCHIVEPATH,OUTPUTPATH)\n",
    "#recordList = fetch_pubmed_preprints(email_address)\n",
    "#has_litcovid = parse_records(recordList,ARCHIVEPATH)\n",
    "#updatedf = transform_results(has_litcovid)\n",
    "#generate_updates(updatedf,OUTPUTPATH)\n",
    "#generate_split_updates(updatedf,OUTPUTPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2674\n",
      "Wall time: 618 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#### Fetch all preprints fromn PubMed\n",
    "\n",
    "#handle = Entrez.esearch(db=\"pubmed\", RetMax=5000, term=\"(COVID OR SARS OR pandemic OR Coronavirus) AND (preprint[Publication Type])\")\n",
    "handle = Entrez.esearch(db=\"pubmed\", RetMax=5000, term=\"preprint[Publication Type]\")\n",
    "records = Entrez.read(handle)\n",
    "handle.close()\n",
    "recordList = records['IdList']\n",
    "print(len(recordList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    preprintPMID                                  preprint_citation  \\\n",
      "134     34312616  Res Sq. 2021 Jul 20. doi: 10.21203/rs.3.rs-700...   \n",
      "156     34268527  medRxiv. 2021 Jul 7. doi: 10.1101/2021.07.05.2...   \n",
      "\n",
      "    publicationType                                        updatedInfo  \\\n",
      "134      [Preprint]  [J Neurodev Disord. 2021 Sep 1;13(1):31. PMID:...   \n",
      "156      [Preprint]  [N Engl J Med. 2021 Sep 2;385(10):951-953. PMI...   \n",
      "\n",
      "    updatedPMID  \n",
      "134    34465306  \n",
      "156    34260834  \n",
      "Wall time: 22.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#### Parse out the corresponding peer-reviewed version PMIDs\n",
    "resultdf = parse_preprints(recordList)\n",
    "has_update = resultdf.loc[resultdf['updatedInfo']!='could not parse'].copy()\n",
    "has_update['updatedPMID'] = has_update.apply(lambda row: parse_pmid(row['updatedInfo']),axis=1)\n",
    "#pmids = parse_pmid(has_update.iloc[0]['updatedInfo'])\n",
    "print(has_update.head(n=2))\n",
    "with open('data/pubmed_preprints.pickle','wb') as outfile:\n",
    "    pickle.dump(has_update,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pubmed_preprints.pickle','rb') as infile:\n",
    "    has_update = pickle.load(infile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         litcovid             preprint\n",
      "168  pmid34358310  2021.07.08.21259776\n",
      "176  pmid34452509    2021.07.07.451505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2324"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Check if the peer-reviewed version is in our import of LitCovid\n",
    "#### If it is, keep it--otherwise, discard it\n",
    "scriptpath = ''\n",
    "RESULTSPATH = os.path.join(scriptpath,'results/')\n",
    "ARCHIVEPATH = os.path.join(RESULTSPATH,'archives/')\n",
    "OUTPUTPATH = os.path.join(RESULTSPATH,'update dumps/')\n",
    "has_litcovid = parse_records(has_update,ARCHIVEPATH)\n",
    "\n",
    "#### parse out the preprint dois\n",
    "updatedf = transform_results(has_litcovid)\n",
    "print(updatedf.head(n=2))\n",
    "\n",
    "#### export results:\n",
    "generate_updates(updatedf,OUTPUTPATH)\n",
    "generate_split_updates(updatedf,OUTPUTPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches found by preprint matcher:  1704\n",
      "Number of matches found by pubmed pilot:  1259\n",
      "Number of matches found by both:  197\n",
      "Number of matches found only by preprint matcher:  1507\n",
      "Number of matches found only by pubmed pilot:  1062\n",
      "Wall time: 159 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprevious results:\\nNumber of matches found by preprint matcher:  1662\\nNumber of matches found by pubmed pilot:  1259\\nNumber of matches found by both:  194\\nNumber of matches found only by preprint matcher:  1468\\nNumber of matches found only by pubmed pilot:  1065\\nWall time: 178 ms\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#### Check overlap with preprint-matching algorithm results\n",
    "litcovid_matches = read_csv('results/update dumps/litcovid_update_file.tsv', delimiter='\\t',header=0, index_col=0)\n",
    "matcher_litcovid_set = set(litcovid_matches['_id'].unique().tolist())\n",
    "pubmed_litcovid_set = set(has_litcovid['outbreak_update_pmids'].unique().tolist())\n",
    "in_common = matcher_litcovid_set.intersection(pubmed_litcovid_set)\n",
    "preprint_matcher_only = [x for x in list(matcher_litcovid_set) if x not in list(pubmed_litcovid_set)]\n",
    "pubmed_litcovid_only = [x for x in list(pubmed_litcovid_set) if x not in list(matcher_litcovid_set)]\n",
    "\n",
    "print(\"Number of matches found by preprint matcher: \", len(matcher_litcovid_set))\n",
    "print(\"Number of matches found by pubmed pilot: \", len(pubmed_litcovid_set))\n",
    "print(\"Number of matches found by both: \",len(in_common))\n",
    "print(\"Number of matches found only by preprint matcher: \",len(preprint_matcher_only))\n",
    "print(\"Number of matches found only by pubmed pilot: \", len(pubmed_litcovid_only))\n",
    "\n",
    "\"\"\"\n",
    "previous results:\n",
    "Number of matches found by preprint matcher:  1662\n",
    "Number of matches found by pubmed pilot:  1259\n",
    "Number of matches found by both:  194\n",
    "Number of matches found only by preprint matcher:  1468\n",
    "Number of matches found only by pubmed pilot:  1065\n",
    "Wall time: 178 ms\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches found by preprint matcher to review:  3391\n",
      "Number of matches found by pubmed pilot:  1259\n",
      "Number of matches found by both:  452\n",
      "Number of matches found only by preprint matcher to review:  2939\n",
      "Number of matches found only by pubmed pilot:  610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nPrevious results:\\n\\nprint(\"Number of matches found by preprint matcher to review: \", len(manual_check_set))\\nprint(\"Number of matches found by pubmed pilot: \", len(pubmed_litcovid_set))\\nprint(\"Number of matches found by both: \",len(manual_in_common))\\nprint(\"Number of matches found only by preprint matcher to review: \",len(manual_check_only))\\nprint(\"Number of matches found only by pubmed pilot: \", len(pubmed_litcovid_only_truly))\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####Check overlap with the \"needs review matches\"\n",
    "manual_check = read_csv('results/to review/manual_check.txt', delimiter='\\t',header=0,index_col=0)\n",
    "#print(manual_check.head(n=2))\n",
    "manual_check_set = set(manual_check['litcovid'].unique().tolist())\n",
    "manual_in_common = manual_check_set.intersection(pubmed_litcovid_set)\n",
    "manual_check_only = [x for x in list(manual_check_set) if x not in list(pubmed_litcovid_set)]\n",
    "pubmed_litcovid_only_truly = [x for x in list(pubmed_litcovid_only) if x not in list(manual_check_set)]\n",
    "\n",
    "print(\"Number of matches found by preprint matcher to review: \", len(manual_check_set))\n",
    "print(\"Number of matches found by pubmed pilot: \", len(pubmed_litcovid_set))\n",
    "print(\"Number of matches found by both: \",len(manual_in_common))\n",
    "print(\"Number of matches found only by preprint matcher to review: \",len(manual_check_only))\n",
    "print(\"Number of matches found only by pubmed pilot: \", len(pubmed_litcovid_only_truly))\n",
    "\n",
    "\"\"\"\n",
    "Previous results:\n",
    "\n",
    "print(\"Number of matches found by preprint matcher to review: \", len(manual_check_set))\n",
    "print(\"Number of matches found by pubmed pilot: \", len(pubmed_litcovid_set))\n",
    "print(\"Number of matches found by both: \",len(manual_in_common))\n",
    "print(\"Number of matches found only by preprint matcher to review: \",len(manual_check_only))\n",
    "print(\"Number of matches found only by pubmed pilot: \", len(pubmed_litcovid_only_truly))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  preprint journal  counts\n",
      "0            ArXiv      28\n",
      "1         ChemRxiv      15\n",
      "2           Res Sq      74\n",
      "3             SSRN       8\n",
      "4          bioRxiv     262\n",
      "5          medRxiv     234\n",
      "['34268505', '34189526', '34100014', '34013272', '34013266', '33948598', '33948597', '33948591', '33948588', '33907753', '33907751', '33907745', '33907744', '33880477', '33880474', '33880472', '33880470', '33880469', '33880467', '33851169', '33851167', '33851166', '33851163', '33851160', '33851157', '33851156', '33851155', '33851154', '33821272', '33821270', '33821269', '33821266', '33821264', '33791706', '33791705', '33791703', '33791699', '33791696', '33791695', '33791692', '33758866', '33758865', '33758864', '33758863', '33758861', '33758856', '33758850', '33758849', '33758848', '33758845', '33758842', '33758838', '33758837', '33758835', '33688660', '33688659', '33688658', '33688657', '33688655', '33688650', '33688648', '33688647', '33688646', '33688643', '33655253', '33655252', '33655251', '33655248', '33655245', '33655244', '33619493', '33619492', '33619491', '33619490', '33619488', '33619487', '33619486', '33619485', '33619483', '33619482', '33619479', '33594370', '33594365', '33594361', '33594360', '33564771', '33564770', '33564768', '33564765', '33564764', '33564763', '33564760', '33532782', '33532781', '33532777', '33532776', '33532774', '33532773', '33532772', '33532765', '33501433', '33469578', '33447831', '33442700', '33442696', '33442689', '33442686', '33442685', '33442684', '33442683', '33442682', '33398289', '33398286', '33398281', '33398280', '33398279', '33398278', '33398277', '33398274', '33398272', '33398270', '33398269', '33398268', '33398267', '33398266', '33330871', '33330865', '33330864', '33330863', '33330861', '33300001', '33300000', '33299994', '33299993', '33299992', '33299991', '33269352', '33269348', '33269347', '33269346', '33236013', '33236010', '33236008', '33236006', '33200136', '33200128', '33173874', '33173872', '33173871', '33173866', '33173864', '33140051', '33140048', '33140043', '33106809', '33106807', '33106805', '33083806', '33083804', '33083800', '33083798', '33052349', '33052348', '33052345', '33052340', '33052338', '33052333', '33024975', '33024973', '33024970', '33024968', '33024967', '32995796', '32995792', '32995790', '32995784', '32995783', '32995781', '32995776', '32995774', '32995771', '32995770', '32995767', '32935108', '32935102', '32935101', '32935096', '32935094', '32908985', '32869033', '32869023', '32839772', '32817943', '32817935', '32793913', '32793912', '32793910', '32793902', '32766589', '32766588', '32766587', '32766581', '32743587', '32743586', '32743581', '32699851', '32676605', '32676599', '32676596', '32637958', '32637944', '32607508', '32607506', '32596695', '32587976', '32587975', '32587974', '32587973', '32587959', '32577660', '32577659', '32577658', '32577652', '32577649', '32577646', '32577642', '32577641', '32577637', '32577631', '32511409', '32511407', '32511405', '32511404', '32511402', '32511401', '32511399', '32511392', '32511390', '32511383', '32511374', '32511373', '32511371', '32511368', '32511365', '32511360', '32511352', '32511351', '32511347', '32511345', '32511343', '32511340', '32511333', '32511330', '32511321', '32511320', '32511318', '32511315', '32511311', '32511304', '32511297', '32511294', '32510524']\n"
     ]
    }
   ],
   "source": [
    "pubmed_unique_pilot = has_litcovid.loc[has_litcovid['outbreak_update_pmids'].isin(pubmed_litcovid_only_truly)]\n",
    "print(pubmed_unique_pilot.groupby('preprint journal').size().reset_index(name=\"counts\"))\n",
    "print(pubmed_unique_pilot['preprintPMID'].loc[pubmed_unique_pilot['preprint journal']=='bioRxiv'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33948449 ArXiv. 2020 Jan 15. pii: 2001.05099. ['Preprint'] ['Biometrics. 2021 Aug 9;:. PMID: 34374071']\n"
     ]
    }
   ],
   "source": [
    "#### Unit text\n",
    "\n",
    "PMID = \"33948449\"\n",
    "handle = Entrez.efetch(db=\"pubmed\", id=PMID, rettype=\"medline\", retmode=\"text\")\n",
    "records = Medline.parse(handle) ##parses pubmed entry for that ID and records the author\n",
    "results = []\n",
    "for record in records:\n",
    "    rec_dict = {\n",
    "        'preprintPMID':record['PMID'],\n",
    "        'preprint_citation':record['SO']\n",
    "        'publicationType':record['PT']\n",
    "        'updatedIn':record['UIN']\n",
    "    }\n",
    "    try:\n",
    "        tmp = record['UIN']\n",
    "        tmplist = tmp.split(':')\n",
    "        UIN_PMID = tmplist[-1]\n",
    "        rec_dict['updated in']=UIN_PMID\n",
    "    except:\n",
    "        rec_dict['updated in']='could not parse'\n",
    "    results.append(rec_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.21203/rs.3.rs-700296.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "test = ['10.21203/rs.3.rs-700296/v1.','10.1101/2021.07.08.21259776.','10.1101/2021.07.07.451505.']\n",
    "test1 = re.sub(r\"\\/v\\d\",\"\",test[0])\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172853\n"
     ]
    }
   ],
   "source": [
    "with open('results/archives/all_litcovid_dict.txt','rb') as infile:\n",
    "    all_litcovid_dict = pickle.load(infile)\n",
    "print(len(all_litcovid_dict['2021-09-21']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative method for checking preprint matcher vs pubmed pilot\n",
    "To investigate the precision and accuracy of the results from the preprint matcher, this notebook will:\n",
    "1. Pull all LitCovid IDs with a 'corrections' field\n",
    "2. Filter only for 'corrections' fields where the values is 'update of' (litcovid itself does not contain preprints, so the corresponding field, 'update in', should not be present)\n",
    "3. Pull the corresponding pmid\n",
    "4. Map the pmid via doi matching to biorxiv/medrxiv preprints\n",
    "5. Analyze the results for number of true positives, false positives, and false negatives to get an idea of precision and sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch all LitCovid IDs with a 'corrections' field from the API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter for 'corrections' field where value contains 'update of'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter for 'corrections' field where value contains 'preprint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch Retraction links: ROF - Obes Res Clin Pract. 2020 Jul - Aug;14(4):295-300. PMID: 32660813"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
